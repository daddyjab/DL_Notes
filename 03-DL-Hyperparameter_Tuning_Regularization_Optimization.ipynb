{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning Notes - Hyperparameter Tuning, Regularization, Optimization\n",
    "* Author: Jeffery Brown\n",
    "* Topic: Deep Learning\n",
    "* GitHub Repo: https://github.com/daddyjab/DL_Notes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"blue\">Summary</font>\n",
    "This Jupyter Notebook provides explores hyperparameter tuning, regularization, and optimization of a deep neural network.\n",
    "\n",
    "TBD\n",
    "\n",
    "<!--\n",
    "\n",
    "1. First, key concepts are introduced:\n",
    "\n",
    "    * A representation of a neural network node is introduced and key elements are described\n",
    "    * Forward and Backward Propagation and their role in calculation of predictions and loss/cost (Forward Propagation) and in optimization of model coeffiencients using gradient descent (Backward Propagation) are discussed.\n",
    "    * Python code snippets for performing the calculations is then shown, including use of the `numpy` library for vector and matrix calculations.\n",
    "    \n",
    "2. Next the single node neural network is implemented:\n",
    "\n",
    "    * Dependencies and the MNIST dataset of handwritten digits 0 through 9 are loaded\n",
    "    * Dataset is explored, including checking for missing or invalid values\n",
    "    * The training and testing labels are changed from an integer 0 to 9 matching the handwritten digit image, to a 1 or 0 indicating that the image is (1) or is not (0) a target single digit selected for the analysis, and a helper function is defined and used to plot a sample of digits and their associated labels\n",
    "    * Next, a class `SingleNode()` is defined that comprises the neural network node model, including methods for instantiation, parameter checking, fitting, prediction, and evaluation.  Attributes are defined for store key values such as model coefficients, flags indicating the status of fitting, etc.\n",
    "    * The class is then used to instantiate a model, fit the training data to the model, make predictions using training and testing data, and then evaluate the predictions results.  A helper function is defined and used to plot the model fitting history, which are shown in a figure below.\n",
    "    \n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "\n",
    "<!-- \n",
    "\n",
    "The single node neural network was used fitted using 60,000 training examples in batches of 32 examples per iteration.  The results for some digits were very good, while the probably of correctly predicting the target digit was lower with other digits.\n",
    "* With `SINGLE_TARGET_DIGIT = 1`, the model performed well, which might be expected since the digit `1` is fairly different in appearance than other digits 0 and 2 through 9.\n",
    "\n",
    "| <b>Table DL-01-A: Single Node Neural Network Performance - Single Target Digit = 1</b> |\n",
    "|:--------------------------------------------------------------------------------------:|\n",
    "\n",
    "|            | Training Data | Testing Data |\n",
    "|:------------|:---------------:|:--------------:|\n",
    "| Count of Examples | 60,000 | 10,000 |\n",
    "| Count of Target Digit in Examples | 6,742 (11.2%) | 1,135 (11.3%) |\n",
    "| Accuracy | 0.9840 | 0.9861 |\n",
    "| Probability of Predicting Correctly<br>when Example is the Target Digit | 0.9058 | 0.9075 |\n",
    "| Probability of Predicting Correctly<br>when Example is Not the Target Digit | 0.9939 | 0.9962 |\n",
    "| Fitting Epochs (Iterations) | 300 | n/a |\n",
    "| Fitting Batch Size | 32 | n/a |\n",
    "| Minimum Batch Loss | 0.0199 @ Epoch 206 | n/a |\n",
    "\n",
    "<br>\n",
    "\n",
    "* However, with `SINGLE_TARGET_DIGIT = 3`, a digit that is more easily confused with other digits, the model performed more poorly.\n",
    "    * The probability of the model correctly predicting the target digit = 3 is low at 0.6525, reflecting the more difficult challenge in distinguishing 3 from digits such as 0 or 8.  The model is bias towards digits being non-target (vs. being the target digit 3).\n",
    "    * The overall accuracy is high, but this is mainly because 88.7% of examples are *not* the target digit 3, and correct predictions of digits as being non-target is good at 0.9945.\n",
    "\n",
    "| <b>Table DL-01-B: Single Node Neural Network Performance - Single Target Digit = 3</b> |\n",
    "|:--------------------------------------------------------------------------------------:|\n",
    "\n",
    "|            | Training Data | Testing Data |\n",
    "|:------------|:---------------:|:--------------:|\n",
    "| Count of Examples | 60,000 | 10,000 |\n",
    "| Count of Target Digit in Examples | 6,131 (10.2% of total) | 1,010 (10.1% of total) |\n",
    "| Accuracy | 0.9581 | 0.9600 |\n",
    "| Probability of Predicting Correctly<br>when Example is the Target Digit | 0.6462 | 0.6525 |\n",
    "| Probability of Predicting Correctly<br>when Example is Not the Target Digit | 0.9936 | 0.9945 |\n",
    "| Fitting Epochs (Iterations) | 300 | n/a |\n",
    "| Fitting Batch Size | 32 | n/a |\n",
    "| Minimum Batch Loss | 0.0560 @ Epoch 128 | n/a |\n",
    "\n",
    "<br><br>\n",
    "* Going foward, the single node  neural network class can be modified to implement more capable neural networks with multiple nodes and layers.\n",
    "\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TBD\n",
    "\n",
    "<!--\n",
    "\n",
    "| Figure DL-01-C: Model Fit History for a Single Node Neural Network - Single Target Digit = 1 | Figure DL-01-D: Model Fit History for a Single Node Neural Network - Single Target Digit = 3 |\n",
    "|:----------:|:----------:|\n",
    "| ![Figure DL-01-C: Model Fit History for a Single Node Neural Network - Single Target Digit = 1...](docs/DL-01-Figure-C-Model_Fit_History-Target_1.png \"Figure DL-01-C: Model Fit History for a Single Node Neural Network - Single Target Digit = 1\") | ![Figure DL-01-D: Model Fit History for a Single Node Neural Network - Single Target Digit = 3...](docs/DL-01-Figure-D-Model_Fit_History-Target_3.png \"Figure DL-01-D: Model Fit History for a Single Node Neural Network - Single Target Digit = 3\") |\n",
    "\n",
    "<br><br>\n",
    "\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TBD\n",
    "\n",
    "<!--\n",
    "| Figure DL-01-C: Model Fit History for a Single Node Neural Network - Single Target Digit = 1 |\n",
    "|:----------:|\n",
    "| ![Figure DL-01-C: Model Fit History for a Single Node Neural Network - Single Target Digit = 1...](docs/DL-01-Figure-C-Model_Fit_History-Target_1.png \"Figure DL-01-C: Model Fit History for a Single Node Neural Network - Single Target Digit = 1\") |\n",
    "\n",
    "<br><br>\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TBD\n",
    "<!--\n",
    "| Figure DL-01-D: Model Fit History for a Single Node Neural Network - Single Target Digit = 3 |\n",
    "|:----------:|\n",
    "| ![Figure DL-01-D: Model Fit History for a Single Node Neural Network - Single Target Digit = 3...](docs/DL-01-Figure-D-Model_Fit_History-Target_3.png \"Figure DL-01-D: Model Fit History for a Single Node Neural Network - Single Target Digit = 3\") |\n",
    "\n",
    "<br><br>\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"red\"> IMPORTANT </font>\n",
    "For introductory notes regarding neural networks, see:\n",
    "* [01-DL-Single_Node_Neural_Network (Jupyter Notebook)](https://github.com/daddyjab/DL_Notes/blob/master/01-DL-Single_Node_Neural_Network.ipynb), which includes discussion of:\n",
    "    * Representation of a Single Neuron (Node)\n",
    "    * Forward and Backward Propagation\n",
    "    * Activation Functions\n",
    "    * Loss Function\n",
    "    * Cost Function\n",
    "    * Forward Propagation Calculations\n",
    "    * Optimization using Gradient Descent\n",
    "    * Backward Propagation Calculations\n",
    "    * Application of the single node neural network to classification of handwritten digits 0 to 9 as a single target digit or not the target digit.\n",
    "\n",
    "<P>\n",
    "    \n",
    "* [02-DL-Deep_Neural_Network (Jupyter Notebook)](https://github.com/daddyjab/DL_Notes/blob/master/02-DL-Deep_Neural_Network.ipynb), which includes discussion of:\n",
    "    * Representation of Neural Network with Multiple Layers\n",
    "    * File \"NN_Support\" - Activation, Evaluation, Plotting Functions: `sigmoid`, `relu`, `leaky_relu`, `evaluate`, `plot_fit_history`\n",
    "    * File \"Class_Multilayer_NN\" - Multilayer Neural Network Class `Multilayer_NN`, with public methods: `configure`, `fit`, `predict`, `get_hist`, `get_config`, \n",
    "    * Application of the multilayer neural network to classification of handwritten digits 0 to 9 as a single target digit or not the target digit.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TBD\n",
    "<!--\n",
    "\n",
    "## <font color=\"blue\"> Representation of Neural Network with Multiple Layers </font>\n",
    "A <b>Neural Network</b> with multiple layers can be represented as shown in Figure DL-02-A: Representation of a Neural Network with Multiple Layers.\n",
    "<P>\n",
    "\n",
    "| Figure DL-02-A: Representation of a Neural Network with Multiple Layers |\n",
    "|:----------:|\n",
    "| ![Figure DL-02-A: Representation of a Neural Network with Multiple Layers is Loading...](docs/DL-02-Figure-A-Neural_Network_Multiple_Layers.png \"Figure DL-02-A: Representation of a Neural Network with Multiple Layers\") |\n",
    "\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forward Propagation Terms:\n",
    "    \n",
    "| Term<br>(for Layer $l$<br>of $L$ total layers) | Description | Definition | Dimensions<br>(rows, columns)|\n",
    "|:----:|:-----------:|:----------------------------------------:|:------------------:|\n",
    "| Input $X$ (or $A^{[0]}$) | Input features of the training or testing examples | Matrix of $n_x$ features for each of $m$ examples | ( $n_x$ features, $m$ examples )\n",
    "| Actual Output $Y$ | Actual labels associated with the training or testing examples | Matrix with $n_y$ outputs for each of $m$ examples | ( $n_y$ outputs, $m$ examples )\n",
    "| Weights $W^{[l]}$ | Weighting coefficients | Matrix of coefficients mapping $n^{[l-1]}$ outputs from the previous layer to $n^{[l]}$ outputs in the current layer| ( $n^{[l]}$ outputs in layer $l$,<br>$n^{[l-1]}$ outputs in layer $l-1$ )\n",
    "| Bias $b^{[l]}$ | Bias coefficients | Vector of coefficients independent of the outputs from the previous layer | ( $n^{[l]}$ units in layer $l$, 1)\n",
    "| Linear function $Z^{[l]}$ | A linear function of the outputs from the previous layer $A^{[l-1]}$ using coefficients $W$ and $b$ | Matrix $Z^{[l]}~=~W^T A^{[l-1]}+b$ | ( $n^{[l]}$ outputs in layer $l$, $m$ examples )\n",
    "| Activation $A^{[l]}$, with:<br>Input $A^{[0]} = X$<br>Predicted Output $A^{[L]} ~=~ \\widehat{Y}$ | Predicted output for the layer based upon output of the layers and an activation function | Matrix $A^{[l]}~=~g^{[l]}(~Z^{[l]}~)$ | ( $n^{[l]}$ outputs in layer $l$, $m$ examples )\n",
    "| Activation Function $g^{[l]}(z)$ | A function which transforms the output of the linear function $z$ and is generally a nonlinear function, such as: sigmoid $\\sigma$, TanH, ReLU, Leaky ReLU, etc. | See [01-DL-Single_Node_Neural_Network (Jupyter Notebook)](https://github.com/daddyjab/DL_Notes/blob/master/01-DL-Single_Node_Neural_Network.ipynb) for the definition of several activation functions $g(z)$ and their derivatives $g^{\\prime}(z)$  | n/a |\n",
    "| Cost Function $J(w,~b)$ | *For a multiple examples*, a measure of the error between the predicted $A^{[L]}$ and actual $Y$ outputs of the neural network | $\\eqalignno {\n",
    "J(w,~b)\n",
    "&= {1 \\over m} \\sum_{i=1}^m \\mathscr{L}(a,~y)\\cr\n",
    "&=- {1 \\over m} \\sum_{i=1}^m \\left [ Y \\log{(A^{[L]}) } + (1-Y) \\log{(1-A^{[L]})} \\right ]\n",
    "}$ | (1, 1) |\n",
    "| Loss Function $\\mathscr{L}(a,~y)$ | *For a single example*, a measure of the error between the predicted $A^{[L]}$ and actual $Y$ outputs of the neural network | $\\mathscr{L}(a,~y)=-(y\\log{(a)}+(1-y)\\log{(1-a)}$ | (1, 1) |\n",
    "| ------------------------------------- | ----------------- | ------------------------------------------------------------------------------| ---------------------------------------------------------- |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Backward Propagation Terms:\n",
    "\n",
    "| Term<br>(for Layer $l$<br>of $L$ total layers) | Description | Definition | Dimensions<br>(rows, columns)|\n",
    "|:----:|:-----------:|:----------------------------------------:|:------------------:|\n",
    "| $dA^{[l]}$ | Partial derivative ${ {\\partial \\mathscr{L}(a,~y)} \\over {\\partial a} }$, the change in loss $\\mathscr{L}(a,~y)$ by the change in $A$ | $\\eqalignno {\n",
    "dA^{[L]} &= - { { Y \\over { A^{[L]} } } + { {(1-Y)} \\over { (1-A^{[L]}) } } }\\cr\n",
    "dA^{[l-1]} &= W^{[l]^{T}} dZ^{[l]}\\cr\n",
    "}$ | ( $n^{[l]}$ outputs in layer $l$, $m$ examples )\n",
    "| $dZ^{[l]}$ | Partial derivative ${ {\\partial \\mathscr{L}(a,~y)} \\over {\\partial z} }$, the change in loss $\\mathscr{L}(a,~y)$ by the change in $Z$ | $\\eqalignno {\n",
    "dZ^{[L]} &= A^{[L]} - Y\\cr\n",
    "dZ^{[l-1]} &= dA^{[l-1]} * g^{\\prime [l-1]}( Z^{[l-1]} )\\cr\n",
    "&= W^{[l]^{T}} dZ^{[l]} * g^{\\prime [l-1]}( Z^{[l-1]} )\\cr\n",
    "}$ | ( $n^{[l]}$ outputs in layer $l$, $m$ examples )\n",
    "| $dW^{[l]}$ | Partial derivative ${ {\\partial J(w,~b)} \\over {\\partial W} }$, the change in cost $J(w,~b)$ by the change in $W$.<br>Used to adjust the Weights $W$ during each iteration, scaled by the learning rate $\\alpha$. | $\\eqalignno {\n",
    "dW^{[l]} &= {1 \\over m} dZ^{[l]} A^{[l-1]^{T}}\\cr\n",
    "W^{[l]} &= W^{[l]} - \\alpha ~ dW^{[l]}\n",
    "}$ | ( $n^{[l]}$ outputs in layer $l$,<br>$n^{[l-1]}$ outputs in layer $l-1$ )\n",
    "| $db^{[l]}$ | Partial derivative ${ {\\partial J(w,~b)} \\over {\\partial b} }$, the change in cost $J(w,~b)$ by the change in $b$.<br>Used to adjust the Bias $b$ during each iteration, scaled by the learning rate $\\alpha$. | $\\eqalignno {\n",
    "db^{[l]} &= {1 \\over m} \\sum_{i=1}^m dZ^{[l]}\\cr\n",
    "b^{[l]} &= b^{[l]} - \\alpha ~ db^{[l]}\n",
    "}$ | ( $n^{[l]}$ outputs in layer $l$, 1 )\n",
    "| ------------------------------------- | ----------------- | ------------------------------------------------------------------------------| ---------------------------------------------------------- |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dependencies - Standard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "nbpresent": {
     "id": "828c2e12-b1c6-4994-8f55-ce86373b6c97"
    },
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Jeff's \"standard\" list of libraries to import  - overkill, but keeping them all for convenience... :)\n",
    "\n",
    "%matplotlib inline\n",
    "# %matplotlib notebook\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from mpl_toolkits.mplot3d import Axes3D    # Support 3D graphing\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas.plotting import table\n",
    "import math\n",
    "import random\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "\n",
    "# Visualization\n",
    "import graphviz\n",
    "import pydotplus\n",
    "\n",
    "from IPython.display import Image\n",
    "\n",
    "# # Machine Learning - Data Preparation and Pre-Processing\n",
    "# from sklearn.model_selection import train_test_split # Split data into training and testing samples\n",
    "# from sklearn.model_selection import cross_val_score  # Score a model using k-fold or other cross validation\n",
    "\n",
    "# from sklearn.preprocessing import OneHotEncoder   # Convert categorical integer features (X) to One-Hot encoded values\n",
    "# from sklearn.preprocessing import LabelEncoder    # Convert categorical labeled values to categorical integer values\n",
    "# from sklearn.preprocessing import LabelBinarizer  # Convert categorical labeled values to Binary encoded values\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler  # Scale numerical features to standard normal distribution\n",
    "from sklearn.preprocessing import MinMaxScaler    # Scale numerical values based upon mix/max values\n",
    "\n",
    "# # Machine Learning - Sci-Kit Learn - Models - Regression\n",
    "# from sklearn.linear_model import LinearRegression  # TBD\n",
    "# from sklearn.linear_model import Lasso             # TBD\n",
    "# from sklearn.linear_model import Ridge             # TBD\n",
    "# from sklearn.linear_model import ElasticNet        # TBD\n",
    "\n",
    "# # Machine Learning - Sci-Kit Learn - Models - Classification\n",
    "# from sklearn.linear_model import LogisticRegression   # Logistic Regression Classifier\n",
    "# from sklearn import tree                              # Decision Tree Classifier\n",
    "# from sklearn.ensemble import RandomForestClassifier   # Random Forest Classifier\n",
    "# from sklearn import svm                               # Support Vector Machine Classifier\n",
    "# from sklearn.neighbors import KNeighborsClassifier    # K-Nearest Neighbors (KNN)\n",
    "\n",
    "# # Machine Learning - GridSearch for Hyper-Parameter tuning\n",
    "# from sklearn.model_selection import GridSearchCV      # Grid Search\n",
    "\n",
    "# # Machine Learning - Quantify Model Performance\n",
    "# from sklearn.metrics import mean_squared_error    # Mean Squared Error (MSE) metric\n",
    "# from sklearn.metrics import r2_score              # R-squared (Coefficient of Determination) metric\n",
    "# from sklearn.metrics import confusion_matrix      # Generate a confusion matrix (actual vs. predicted counts)\n",
    "# from sklearn.metrics import classification_report # Calculate metrics for prediction performance\n",
    "# from sklearn.metrics import precision_score       # Calculate the precision: Tp / (Tp + Fp) => Ability to avoid false negatives\n",
    "# from sklearn.metrics import recall_score          # Calculate the recall: Tp / (Tp + Fn) => Ability to find all positive samples\n",
    "# from sklearn.metrics import f1_score              # Calculate the F1 score: 2*(precision*recall)/(precision+recall)\n",
    "\n",
    "# # Machine Learning - Dataset Generation\n",
    "# from sklearn.datasets import make_regression     # Generate linear data\n",
    "# from sklearn.datasets import make_s_curve        # Generate nonlinear data\n",
    "# from sklearn.datasets import make_blobs          # Generate blobs for classification\n",
    "# from sklearn.datasets import make_circles        # Generate circles for classification\n",
    "# from sklearn.datasets import load_iris           # Sample multi-class dataset for classification\n",
    "# from sklearn.datasets import make_classification # Generate datasets for classification\n",
    "\n",
    "# # Machine Learning - Keras (Tensorflow) - Models\n",
    "# from keras.models import Sequential               # Sequential model serving as foundation for neural network\n",
    "# from keras.layers import Dense                    # Nodes for specifying input, hidden, and output layers\n",
    "\n",
    "# # Machine Learning - Keras (Tensorflow) - Encoding\n",
    "# from keras.utils import to_categorical            # One-Hot Encoder provided through Keras\n",
    "\n",
    "# # Machine Learning - Keras (Tensorflow) - Other related Tools\n",
    "# from keras.utils import plot_model                # Plot a neural network model\n",
    "# from keras.models import load_model               # Load a saved machine learning model\n",
    "# from keras.preprocessing import image             # Loads an image for application of machine learning\n",
    "# from keras.preprocessing.image import img_to_array # Converts an image to a numpy array\n",
    "\n",
    "# Machine Learning - Keras (Tensorflow) -  Dataset Generation\n",
    "from keras.datasets import mnist                  # Images: Handwritten digits 0-9 (28x28 grayscale, 60K train, 10K test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dependency: \"NN_Support\" (Activation, Evaluation, Plotting Functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from NN_Support import (sigmoid, relu, leaky_relu, evaluate, plot_fit_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Array: [-0.8  0.   0.8]\n",
      "Sigmoid: [0.31002552 0.5        0.68997448], Derivative of Sigmoid: [0.2139097 0.25      0.2139097]\n",
      "ReLU: [0.  0.  0.8], Derivative of ReLU: [0 0 1]\n",
      "Leaky ReLU: [-0.008  0.     0.8  ], Derivative of Leaky ReLU: [0.01 0.01 1.  ]\n"
     ]
    }
   ],
   "source": [
    "# TRYIT: Activation Functions\n",
    "test_array_config = 0.8\n",
    "test_array = np.array([-test_array_config, 0, test_array_config])\n",
    "\n",
    "print(f\"Test Array: {test_array}\")\n",
    "print(f\"Sigmoid: {sigmoid( test_array )}, Derivative of Sigmoid: {sigmoid( test_array, True )}\")\n",
    "print(f\"ReLU: {relu( test_array )}, Derivative of ReLU: {relu( test_array, True )}\")\n",
    "print(f\"Leaky ReLU: {leaky_relu( test_array )}, Derivative of Leaky ReLU: {leaky_relu( test_array, True )}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to Evaluate Prediction Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "np.bincount for abc_1 [100 values]: [46 54]\n",
      "np.bincount for abc_2 [100 values]: [51 49]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.49,\n",
       " 'proba_label_1': 0.5306122448979592,\n",
       " 'proba_label_0': 0.4509803921568627}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TRYIT: Evaluate Prediction Accuracy\n",
    "abc_1 = np.squeeze(np.random.randint( 0, 2, size=(1,100) ))\n",
    "abc_2 = np.squeeze(np.random.randint( 0, 2, size=(1,100) ))\n",
    "print(f\"np.bincount for abc_1 [{len(abc_1)} values]: {np.bincount(abc_1)}\")\n",
    "print(f\"np.bincount for abc_2 [{len(abc_2)} values]: {np.bincount(abc_2)}\")\n",
    "evaluate(abc_1, abc_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dependency: \"Class_Multilayer_NN\" (Multilayer Neural Network Class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Class_Multilayer_NN import (Multilayer_NN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: (5, 320), y: (1, 320)\n"
     ]
    }
   ],
   "source": [
    "# TRYIT: Multilayer Neural Network Class\n",
    "all_layers_temp = [5, 2, 1]\n",
    "m_temp = 32*10\n",
    "X_temp = np.random.rand( all_layers_temp[0], m_temp )\n",
    "y_temp = np.random.randint( 0, 2, size = (all_layers_temp[-1], m_temp) )\n",
    "print(f\"X: {X_temp.shape}, y: {y_temp.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# abc = Multilayer_NN()\n",
    "# abc.configure(all_layers_temp)\n",
    "# abc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Multilayer_NN({'is_configured': True, 'is_fitted': False, 'alpha': None, 'lambda': None, 'batch_size': None, 'max_epochs': None, 'm': None, 'n_x': 5, 'n_y': 1, 'L': 2, 'all_layers': [5, 2, 1]})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abc = Multilayer_NN(all_layers_temp)\n",
    "abc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch: 0 => Cost J(w,b)=0.6934, Accuracy=0.3906\n",
      "[Epoch: 1000 => Cost J(w,b)=0.6928, Accuracy=0.4844\n",
      "[Epoch: 2000 => Cost J(w,b)=0.6925, Accuracy=0.4844\n",
      "[Epoch: 3000 => Cost J(w,b)=0.6923, Accuracy=0.4813\n",
      "[Epoch: 4000 => Cost J(w,b)=0.6923, Accuracy=0.4813\n",
      "[Epoch: 5000 => Cost J(w,b)=0.6922, Accuracy=0.4813\n",
      "[Epoch: 6000 => Cost J(w,b)=0.6922, Accuracy=0.4813\n",
      "[Epoch: 7000 => Cost J(w,b)=0.6921, Accuracy=0.4813\n",
      "[Epoch: 8000 => Cost J(w,b)=0.6920, Accuracy=0.4813\n",
      "[Epoch: 9000 => Cost J(w,b)=0.6920, Accuracy=0.4813\n"
     ]
    }
   ],
   "source": [
    "abc.fit(X_temp, y_temp, a_batch_size = 32, a_max_epochs = 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Multilayer_NN({'is_configured': True, 'is_fitted': True, 'alpha': 0.01, 'lambda': 0.0, 'batch_size': 32, 'max_epochs': 10000, 'm': 320, 'n_x': 5, 'n_y': 1, 'L': 2, 'all_layers': [5, 2, 1], 'optim': 'adam', 'beta1': 0.9, 'beta2': 0.999, 'a_epsilon': 1e-07})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 320)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predict_temp = abc.predict(X_temp)\n",
    "y_predict_temp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.51875,\n",
       " 'proba_label_1': 1.0,\n",
       " 'proba_label_0': 0.012820512820512775}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_results = evaluate(y_predict_temp, y_temp)\n",
    "eval_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cost': [0.6934041572634115,\n",
       "  0.6934014301708117,\n",
       "  0.6933829283117918,\n",
       "  0.6933843311827397,\n",
       "  0.6933875835512362,\n",
       "  0.6933542038016374,\n",
       "  0.6933195538959662,\n",
       "  0.6933402301409308,\n",
       "  0.6932951763301889,\n",
       "  0.6932903365374954,\n",
       "  0.6932792894662836,\n",
       "  0.6932748853764847,\n",
       "  0.6932615610357172,\n",
       "  0.6932468302617515,\n",
       "  0.6932629741513399,\n",
       "  0.6932239517778285,\n",
       "  0.6932234238779518,\n",
       "  0.6932257971746514,\n",
       "  0.6931940175510789,\n",
       "  0.6932045026219015,\n",
       "  0.6931809058292364,\n",
       "  0.6931877242169788,\n",
       "  0.6931781015423006,\n",
       "  0.6931861372878,\n",
       "  0.693193704934636,\n",
       "  0.6931687476246879,\n",
       "  0.6931642780690167,\n",
       "  0.6931799267701806,\n",
       "  0.6931392047231778,\n",
       "  0.6931804678034622,\n",
       "  0.6931581966506989,\n",
       "  0.693144899222206,\n",
       "  0.6931311028329368,\n",
       "  0.6931202079945061,\n",
       "  0.6931190666776952,\n",
       "  0.6931471416346479,\n",
       "  0.6931074895249211,\n",
       "  0.6931254913097871,\n",
       "  0.6931140505986899,\n",
       "  0.693115649501073,\n",
       "  0.69312256218102,\n",
       "  0.6931160926456573,\n",
       "  0.6931227645811985,\n",
       "  0.6930847020300643,\n",
       "  0.6930816919612677,\n",
       "  0.6931070070157549,\n",
       "  0.6930762150091985,\n",
       "  0.6930631496489281,\n",
       "  0.6930601205687786,\n",
       "  0.693083400485764,\n",
       "  0.6930655071544536,\n",
       "  0.6930709207385224,\n",
       "  0.693059920521209,\n",
       "  0.6931136073100468,\n",
       "  0.6930682611286223,\n",
       "  0.6930856709601269,\n",
       "  0.6930630692870897,\n",
       "  0.693047322632151,\n",
       "  0.6930607158549696,\n",
       "  0.6930765404099785,\n",
       "  0.693060862935312,\n",
       "  0.6930554571203966,\n",
       "  0.6930467037199198,\n",
       "  0.6930561564809171,\n",
       "  0.6930444395696148,\n",
       "  0.6930692035294872,\n",
       "  0.6930897363045105,\n",
       "  0.693037624923787,\n",
       "  0.6930297921314146,\n",
       "  0.6930697064533919,\n",
       "  0.6930444348987084,\n",
       "  0.6930628261738349,\n",
       "  0.6930161060134888,\n",
       "  0.693040110115593,\n",
       "  0.6930244003577684,\n",
       "  0.6930472696910385,\n",
       "  0.6930517817558609,\n",
       "  0.6930177046176464,\n",
       "  0.6930211601722266,\n",
       "  0.6930185726529177,\n",
       "  0.693041953348,\n",
       "  0.6930283574831673,\n",
       "  0.6930286402912699,\n",
       "  0.6930205012481987,\n",
       "  0.6930155613435901,\n",
       "  0.693025019528539,\n",
       "  0.6930091109434318,\n",
       "  0.6930431313610638,\n",
       "  0.6930331898121803,\n",
       "  0.693008482681298,\n",
       "  0.6930121455565217,\n",
       "  0.6929974103338306,\n",
       "  0.6930255063434034,\n",
       "  0.6929913002030382,\n",
       "  0.6930217478519602,\n",
       "  0.6930202529905068,\n",
       "  0.6930127769460912,\n",
       "  0.693028984902746,\n",
       "  0.6930030633891661,\n",
       "  0.6929999718143394,\n",
       "  0.6930023432839627,\n",
       "  0.6930287107785911,\n",
       "  0.6930108016635392,\n",
       "  0.693001634673026,\n",
       "  0.6930029025639631,\n",
       "  0.693043602540784,\n",
       "  0.69302821104491,\n",
       "  0.6929830983840186,\n",
       "  0.6930242099876796,\n",
       "  0.6930016717910076,\n",
       "  0.6929762434836372,\n",
       "  0.6930188603632663,\n",
       "  0.6929876027934609,\n",
       "  0.692976289001069,\n",
       "  0.6929933046172785,\n",
       "  0.6930098593426058,\n",
       "  0.6930104371227658,\n",
       "  0.6929654638921499,\n",
       "  0.6929821078495036,\n",
       "  0.6929859151318001,\n",
       "  0.6930028677728698,\n",
       "  0.6930026133299395,\n",
       "  0.6929749867114711,\n",
       "  0.6929953749873424,\n",
       "  0.6929801961058845,\n",
       "  0.6929787638578102,\n",
       "  0.6929943735521717,\n",
       "  0.6929931507972708,\n",
       "  0.6930108962694403,\n",
       "  0.6930121967900498,\n",
       "  0.6930027451098695,\n",
       "  0.6929834679469205,\n",
       "  0.6929781133589391,\n",
       "  0.6929893134213377,\n",
       "  0.6929761056960853,\n",
       "  0.692978902266191,\n",
       "  0.6929755900370548,\n",
       "  0.6929821625855338,\n",
       "  0.6930039508098969,\n",
       "  0.692980455084973,\n",
       "  0.6929938455880066,\n",
       "  0.6929931210593884,\n",
       "  0.6929904884171341,\n",
       "  0.692990051648282,\n",
       "  0.6929809478393861,\n",
       "  0.6930214504167578,\n",
       "  0.6929950019833966,\n",
       "  0.6929897884073691,\n",
       "  0.6929942108660117,\n",
       "  0.6929743171156064,\n",
       "  0.6929736128461437,\n",
       "  0.6929829683409385,\n",
       "  0.6929632602505905,\n",
       "  0.6929790417523332,\n",
       "  0.6930025169666216,\n",
       "  0.6929807330743124,\n",
       "  0.6929860255971,\n",
       "  0.6929644537795293,\n",
       "  0.692982459483198,\n",
       "  0.693012227484072,\n",
       "  0.693020594543208,\n",
       "  0.6929782236610479,\n",
       "  0.6929611413439369,\n",
       "  0.692983269333389,\n",
       "  0.692987636840383,\n",
       "  0.6930010599212837,\n",
       "  0.6929885382861936,\n",
       "  0.6930079792597003,\n",
       "  0.6929941235828704,\n",
       "  0.692978878463961,\n",
       "  0.6929868092500059,\n",
       "  0.6929861580613651,\n",
       "  0.6929628956612961,\n",
       "  0.6929759336392595,\n",
       "  0.6929670164287944,\n",
       "  0.6929870865950315,\n",
       "  0.6929751395595912,\n",
       "  0.6929666023158718,\n",
       "  0.6929914809399007,\n",
       "  0.6929768865797166,\n",
       "  0.6929661726570993,\n",
       "  0.6929973206297595,\n",
       "  0.692987289953272,\n",
       "  0.6929623844664331,\n",
       "  0.6929702944852567,\n",
       "  0.6930031529848383,\n",
       "  0.6929968124805188,\n",
       "  0.6929768169988136,\n",
       "  0.6929488457595699,\n",
       "  0.6929678092798955,\n",
       "  0.692974881878629,\n",
       "  0.692979024350356,\n",
       "  0.6929575618552065,\n",
       "  0.6929713521972966,\n",
       "  0.6929772584219116,\n",
       "  0.6929629513656066,\n",
       "  0.6929604385912088,\n",
       "  0.6929681461224231,\n",
       "  0.6929597967908054,\n",
       "  0.6929782675190701,\n",
       "  0.6929822660103578,\n",
       "  0.6929740207107925,\n",
       "  0.6929827362532277,\n",
       "  0.692981060056768,\n",
       "  0.6929516335837083,\n",
       "  0.6929423589983451,\n",
       "  0.6929518832227948,\n",
       "  0.6929604198063334,\n",
       "  0.6929609314125584,\n",
       "  0.6929449754950054,\n",
       "  0.6929708558141782,\n",
       "  0.6929521059342977,\n",
       "  0.6929567804374145,\n",
       "  0.6929685256215299,\n",
       "  0.6929582972133288,\n",
       "  0.692967897389658,\n",
       "  0.6929570065630506,\n",
       "  0.6929692436633472,\n",
       "  0.6929541983158766,\n",
       "  0.692986859033992,\n",
       "  0.6929481938813687,\n",
       "  0.6929631124304632,\n",
       "  0.6929374566874287,\n",
       "  0.6929867569751409,\n",
       "  0.6929537015226861,\n",
       "  0.6929689322388757,\n",
       "  0.6929841934497785,\n",
       "  0.6929642151777675,\n",
       "  0.692960952685679,\n",
       "  0.6929605681217167,\n",
       "  0.692948300381218,\n",
       "  0.692967410095488,\n",
       "  0.6929827392283759,\n",
       "  0.6929403684605028,\n",
       "  0.6929582282781606,\n",
       "  0.6929596840174487,\n",
       "  0.6929500494281152,\n",
       "  0.6929372153105249,\n",
       "  0.6929443987526807,\n",
       "  0.692944614983284,\n",
       "  0.6929534481029618,\n",
       "  0.6929365024574707,\n",
       "  0.692973317628435,\n",
       "  0.6929568905417715,\n",
       "  0.6929876733975882,\n",
       "  0.6929356688791695,\n",
       "  0.6930056543490053,\n",
       "  0.6929538531885371,\n",
       "  0.6929743087493123,\n",
       "  0.6929402753746019,\n",
       "  0.6929752562935738,\n",
       "  0.6929365028860913,\n",
       "  0.6929460996310671,\n",
       "  0.6929764336940996,\n",
       "  0.6929759501396229,\n",
       "  0.6929534079090944,\n",
       "  0.6929404482746733,\n",
       "  0.6929665088071724,\n",
       "  0.69293219077243,\n",
       "  0.692971177690174,\n",
       "  0.6929416023502041,\n",
       "  0.6929469565413628,\n",
       "  0.6929570317998572,\n",
       "  0.6929586924141955,\n",
       "  0.6929405892257026,\n",
       "  0.6929808888307762,\n",
       "  0.6929335868110824,\n",
       "  0.6929513607217899,\n",
       "  0.6929292634070113,\n",
       "  0.6929595401464346,\n",
       "  0.6929629985866931,\n",
       "  0.6929432038451432,\n",
       "  0.6929705014283004,\n",
       "  0.6929444486178016,\n",
       "  0.6929702887492526,\n",
       "  0.6929650613800704,\n",
       "  0.692958848865182,\n",
       "  0.692936233896357,\n",
       "  0.6929223423740498,\n",
       "  0.6929439567991674,\n",
       "  0.6929327634673819,\n",
       "  0.692933421335763,\n",
       "  0.6929539870728085,\n",
       "  0.6929241153043264,\n",
       "  0.6929304344402786,\n",
       "  0.6929538638708742,\n",
       "  0.692937332652822,\n",
       "  0.6929490951722681,\n",
       "  0.6929253355224564,\n",
       "  0.6929481472577473,\n",
       "  0.6929287532701331,\n",
       "  0.6929535898172954,\n",
       "  0.6929545203305041,\n",
       "  0.6929322128301617,\n",
       "  0.6929278604914241,\n",
       "  0.6929273068939846,\n",
       "  0.6929444752388028,\n",
       "  0.6929779165858946,\n",
       "  0.6929253737118192,\n",
       "  0.6929336322901835,\n",
       "  0.692953025567314,\n",
       "  0.6929797344237227,\n",
       "  0.6929281278547692,\n",
       "  0.6929354442412778,\n",
       "  0.6929599952942039,\n",
       "  0.6929412239451476,\n",
       "  0.6929789373294172,\n",
       "  0.6929493684123503,\n",
       "  0.6929222432415083,\n",
       "  0.6929320293936689,\n",
       "  0.6929455877775718,\n",
       "  0.6929380423755229,\n",
       "  0.6929199538841828,\n",
       "  0.6929349532487437,\n",
       "  0.6929387353084377,\n",
       "  0.692937939792266,\n",
       "  0.692951992664266,\n",
       "  0.6929377164886096,\n",
       "  0.6929443474739173,\n",
       "  0.6929134597109027,\n",
       "  0.6929298901218743,\n",
       "  0.6929255934930113,\n",
       "  0.6929368318728666,\n",
       "  0.6929190999549364,\n",
       "  0.6929243368840973,\n",
       "  0.6929512634370049,\n",
       "  0.6929403724154529,\n",
       "  0.6929350408351695,\n",
       "  0.6929190257826213,\n",
       "  0.6929087857263433,\n",
       "  0.6929162440619416,\n",
       "  0.6929473282426482,\n",
       "  0.6929259515698492,\n",
       "  0.6929575895308131,\n",
       "  0.6929170806343573,\n",
       "  0.6929222272549742,\n",
       "  0.6929567195759792,\n",
       "  0.6929410812280028,\n",
       "  0.6929154686887266,\n",
       "  0.6929255851695485,\n",
       "  0.6929276530139115,\n",
       "  0.692924539648289,\n",
       "  0.6929404101524754,\n",
       "  0.6929292427270204,\n",
       "  0.6929242162074135,\n",
       "  0.6929160686879554,\n",
       "  0.6929305064081833,\n",
       "  0.69292331197757,\n",
       "  0.6929907538134483,\n",
       "  0.6929250444877265,\n",
       "  0.6929134934789313,\n",
       "  0.6929343883022104,\n",
       "  0.6929136099827845,\n",
       "  0.6929170469376154,\n",
       "  0.6929363535887869,\n",
       "  0.692924985038135,\n",
       "  0.6929245293334578,\n",
       "  0.6929078157618297,\n",
       "  0.6929014280269208,\n",
       "  0.6929539773012222,\n",
       "  0.6929337754009067,\n",
       "  0.6929087630796912,\n",
       "  0.6929005644117628,\n",
       "  0.6929246584992438,\n",
       "  0.6929152610289294,\n",
       "  0.6929146610800584,\n",
       "  0.6929150984134191,\n",
       "  0.6929236301831501,\n",
       "  0.692923126200961,\n",
       "  0.6929223650297207,\n",
       "  0.6929365926278603,\n",
       "  0.692906748979595,\n",
       "  0.6929490898691345,\n",
       "  0.6929106864739659,\n",
       "  0.6929404928150533,\n",
       "  0.6929174819611611,\n",
       "  0.6929463187522777,\n",
       "  0.6929128116045125,\n",
       "  0.6929013706692102,\n",
       "  0.6929454699451046,\n",
       "  0.6929555048252055,\n",
       "  0.6929446014082811,\n",
       "  0.6929291456047925,\n",
       "  0.6929210719626095,\n",
       "  0.6929030920621153,\n",
       "  0.6928932926737972,\n",
       "  0.6928974233483751,\n",
       "  0.6929011025138199,\n",
       "  0.6929489118662218,\n",
       "  0.6929188247335372,\n",
       "  0.6929182985665026,\n",
       "  0.6928924787271893,\n",
       "  0.6929137338139892,\n",
       "  0.6929072779939744,\n",
       "  0.6929061242065149,\n",
       "  0.6929191138134546,\n",
       "  0.6929251191460899,\n",
       "  0.6929043860602955,\n",
       "  0.6928943055232554,\n",
       "  0.6929102770880691,\n",
       "  0.6928936752520172,\n",
       "  0.6929030001044507,\n",
       "  0.6928874498731926,\n",
       "  0.6929082938377074,\n",
       "  0.6928959134819213,\n",
       "  0.6928983045229734,\n",
       "  0.6929474966597822,\n",
       "  0.6929042931158634,\n",
       "  0.6928884129048669,\n",
       "  0.6928952576030287,\n",
       "  0.6928865223860845,\n",
       "  0.6929289688778293,\n",
       "  0.692923633236636,\n",
       "  0.692891557511947,\n",
       "  0.6929196413493954,\n",
       "  0.6929277428090432,\n",
       "  0.6928979017219176,\n",
       "  0.6928909862690562,\n",
       "  0.6929128243096809,\n",
       "  0.6928814950077854,\n",
       "  0.6929005394042212,\n",
       "  0.6928927190174735,\n",
       "  0.6929072287265553,\n",
       "  0.6928954756872846,\n",
       "  0.6928918421573608,\n",
       "  0.6929346739994913,\n",
       "  0.6928951661105571,\n",
       "  0.6929082755048459,\n",
       "  0.692905199676835,\n",
       "  0.6928917769564347,\n",
       "  0.6928949150845074,\n",
       "  0.6929248145183257,\n",
       "  0.6928913133200366,\n",
       "  0.6928921200814065,\n",
       "  0.6929025856927942,\n",
       "  0.6928879383013823,\n",
       "  0.6928953781119621,\n",
       "  0.692948040453368,\n",
       "  0.6928852783478026,\n",
       "  0.6929232081819425,\n",
       "  0.692878170894233,\n",
       "  0.6929069310586492,\n",
       "  0.6928818767406217,\n",
       "  0.6928890034628664,\n",
       "  0.6929132231577351,\n",
       "  0.6929053345619594,\n",
       "  0.692895136393534,\n",
       "  0.6928886825773172,\n",
       "  0.6928803473687425,\n",
       "  0.692926982260567,\n",
       "  0.6928995248510652,\n",
       "  0.6928695033847189,\n",
       "  0.6929119865312868,\n",
       "  0.692908736786725,\n",
       "  0.6929028465974776,\n",
       "  0.6928902557265981,\n",
       "  0.6928879859214632,\n",
       "  0.6929348993512343,\n",
       "  0.6929323536943562,\n",
       "  0.6929307806930325,\n",
       "  0.6928961595645433,\n",
       "  0.6928781540688124,\n",
       "  0.6928805999034393,\n",
       "  0.6929149671196081,\n",
       "  0.692893581443488,\n",
       "  0.6928856518850577,\n",
       "  0.6929212387980743,\n",
       "  0.6928989002370145,\n",
       "  0.6928760466181039,\n",
       "  0.6928697503666743,\n",
       "  0.6928837721566065,\n",
       "  0.692889250299363,\n",
       "  0.6928833983735474,\n",
       "  0.6928711652419199,\n",
       "  0.692885337487742,\n",
       "  0.6928815381948004,\n",
       "  0.6928860514516907,\n",
       "  0.6929012387423132,\n",
       "  0.6929004347740225,\n",
       "  0.6928858420193511,\n",
       "  0.6928741537562905,\n",
       "  0.6928675249761048,\n",
       "  0.692870837688131,\n",
       "  0.6928784554936954,\n",
       "  0.6928972528724084,\n",
       "  0.6928747780747848,\n",
       "  0.6928875291156248,\n",
       "  0.692892826768011,\n",
       "  0.6929123998180093,\n",
       "  0.6928751716013065,\n",
       "  0.6929216933367667,\n",
       "  0.6928932767809236,\n",
       "  0.692869459509151,\n",
       "  0.6928778597794738,\n",
       "  0.6928691019494779,\n",
       "  0.69286528698596,\n",
       "  0.6928682028638156,\n",
       "  0.6928927229728935,\n",
       "  0.6928883754865229,\n",
       "  0.6928993008639446,\n",
       "  0.6928662026951745,\n",
       "  0.6928811700065654,\n",
       "  0.6928982217531323,\n",
       "  0.6928921770046476,\n",
       "  0.6928693997032787,\n",
       "  0.6928749088832533,\n",
       "  0.6929050457278093,\n",
       "  0.6928889728784746,\n",
       "  0.692885593781203,\n",
       "  0.6928968500434413,\n",
       "  0.6928631879492612,\n",
       "  0.6928637368640256,\n",
       "  0.6928667076597195,\n",
       "  0.6928889233179512,\n",
       "  0.6928891708758453,\n",
       "  0.6928742673645958,\n",
       "  0.6928576909290743,\n",
       "  0.6929003229569457,\n",
       "  0.6929034806051311,\n",
       "  0.6928684539003682,\n",
       "  0.6929037924477184,\n",
       "  0.692869141610098,\n",
       "  0.6928696137930542,\n",
       "  0.6928639597156737,\n",
       "  0.6929008128221366,\n",
       "  0.6928801702811634,\n",
       "  0.6928635862427147,\n",
       "  0.6928678594663431,\n",
       "  0.6928827259795113,\n",
       "  0.6928751098215252,\n",
       "  0.6928743199766585,\n",
       "  0.6928829618944738,\n",
       "  0.6928727972886534,\n",
       "  0.6928684452405837,\n",
       "  0.6928768435297605,\n",
       "  0.6928854823555813,\n",
       "  0.6928744652004026,\n",
       "  0.6928510890024315,\n",
       "  0.692861259967294,\n",
       "  0.6928627829031695,\n",
       "  0.6928766014689314,\n",
       "  0.6928654503354783,\n",
       "  0.6928591347483045,\n",
       "  0.692861358208208,\n",
       "  0.6928674290440929,\n",
       "  0.6928736093708947,\n",
       "  0.692850035700726,\n",
       "  0.6928623687848992,\n",
       "  0.6928667821648868,\n",
       "  0.692853461462931,\n",
       "  0.6928670788120734,\n",
       "  0.6928642124892559,\n",
       "  0.6928772702342099,\n",
       "  0.6928892958664246,\n",
       "  0.6928762521084202,\n",
       "  0.69286138728361,\n",
       "  0.6928740445884147,\n",
       "  0.6928752936528872,\n",
       "  0.6928546762918586,\n",
       "  0.6928472180525949,\n",
       "  0.6928572352247536,\n",
       "  0.6928628656127719,\n",
       "  0.6928711490698969,\n",
       "  0.6928812431300189,\n",
       "  0.6928687616934674,\n",
       "  0.692871630472425,\n",
       "  0.6928804238229327,\n",
       "  0.6928687011610373,\n",
       "  0.692889338538057,\n",
       "  0.6928729068297536,\n",
       "  0.6928654403352075,\n",
       "  0.69284896843691,\n",
       "  0.692883571574508,\n",
       "  0.6928483357552596,\n",
       "  0.6928679542636866,\n",
       "  0.6928340136987369,\n",
       "  0.6929014613538276,\n",
       "  0.6928744690004105,\n",
       "  0.6928413126161601,\n",
       "  0.6928742925323537,\n",
       "  0.6928549450529046,\n",
       "  0.6928463952109151,\n",
       "  0.6928642923168751,\n",
       "  0.6928495389262659,\n",
       "  0.6928543594865546,\n",
       "  0.6928659734643559,\n",
       "  0.6928632186611674,\n",
       "  0.6928369314604962,\n",
       "  0.6928493406779328,\n",
       "  0.6928526151281753,\n",
       "  0.6928557461343902,\n",
       "  0.6928700558674998,\n",
       "  0.6928501340213626,\n",
       "  0.6928759861806573,\n",
       "  0.6928807774273122,\n",
       "  0.6928415532745346,\n",
       "  0.6928743975976782,\n",
       "  0.6928401477601064,\n",
       "  0.6928350631886104,\n",
       "  0.6928431345448561,\n",
       "  0.6928651911333877,\n",
       "  0.6928634150156521,\n",
       "  0.692861739333461,\n",
       "  0.6928616810734886,\n",
       "  0.6928456203164535,\n",
       "  0.6928404435606996,\n",
       "  0.6928490087072305,\n",
       "  0.6928544055609918,\n",
       "  0.6928502512114678,\n",
       "  0.6928747277973002,\n",
       "  0.6928363673991936,\n",
       "  0.6928644754887616,\n",
       "  0.6928653825734099,\n",
       "  0.6928337159814956,\n",
       "  0.6928491677041952,\n",
       "  0.6928344750589664,\n",
       "  0.6928472454737244,\n",
       "  0.6928376867405761,\n",
       "  0.6928633836530765,\n",
       "  0.692875596557026,\n",
       "  0.6928416012892423,\n",
       "  0.6928732299978139,\n",
       "  0.6928514545233375,\n",
       "  0.6928395380749583,\n",
       "  0.6928811080704463,\n",
       "  0.6928756655966455,\n",
       "  0.6928623441091679,\n",
       "  0.6928191001675786,\n",
       "  0.6928468320875665,\n",
       "  0.692847409652896,\n",
       "  0.6928399549451264,\n",
       "  0.6928447606319461,\n",
       "  0.692834384529897,\n",
       "  0.6928871150244535,\n",
       "  0.692822967241762,\n",
       "  0.6928464266350428,\n",
       "  0.6928400051420524,\n",
       "  0.6928579209263541,\n",
       "  0.6928604292074843,\n",
       "  0.6928205878189425,\n",
       "  0.6928515310745477,\n",
       "  0.6928393666106412,\n",
       "  0.69285230011413,\n",
       "  0.692858194261452,\n",
       "  0.6928287675900121,\n",
       "  0.6928322788347403,\n",
       "  0.692875136572574,\n",
       "  0.6928394393745253,\n",
       "  0.6928350966010538,\n",
       "  0.6928311139310839,\n",
       "  0.6928562831626282,\n",
       "  0.6928602772182465,\n",
       "  0.6928376628437664,\n",
       "  0.6928244640876302,\n",
       "  0.6928556130906361,\n",
       "  0.6928319128685028,\n",
       "  0.6928340700575611,\n",
       "  0.6928571517045161,\n",
       "  0.6928309404774343,\n",
       "  0.692850679241834,\n",
       "  0.6928397250469284,\n",
       "  0.6928244569179808,\n",
       "  0.6928417358330441,\n",
       "  0.6928153225961025,\n",
       "  0.6928297283646556,\n",
       "  0.6928421810211114,\n",
       "  0.6928215742803937,\n",
       "  0.6928317168330596,\n",
       "  0.6928386129580767,\n",
       "  0.6928432904708429,\n",
       "  0.6928479905724135,\n",
       "  0.6928421032419625,\n",
       "  0.6928410805728646,\n",
       "  0.6928597664165952,\n",
       "  0.6928559912050595,\n",
       "  0.6928202221826013,\n",
       "  0.6928379465648743,\n",
       "  0.6928307877381847,\n",
       "  0.6928533197369744,\n",
       "  0.6928780963766905,\n",
       "  0.6928543464198718,\n",
       "  0.6928435041595767,\n",
       "  0.6928284676489547,\n",
       "  0.6928512495319566,\n",
       "  0.6928289507300889,\n",
       "  0.6928282315281903,\n",
       "  0.6928227805850489,\n",
       "  0.692827058061779,\n",
       "  0.6928472376266848,\n",
       "  0.6928254970125785,\n",
       "  0.6928324912601507,\n",
       "  0.6928501472366375,\n",
       "  0.6928356418169488,\n",
       "  0.6928405041469817,\n",
       "  0.6928168948416283,\n",
       "  0.692839833555948,\n",
       "  0.6928313668957224,\n",
       "  0.6928162056493548,\n",
       "  0.6928376191722834,\n",
       "  0.6928273412851377,\n",
       "  0.6928184136739265,\n",
       "  0.6928418045878236,\n",
       "  0.6928456255027464,\n",
       "  0.6928263124910556,\n",
       "  0.6928485721898551,\n",
       "  0.6928200776469058,\n",
       "  0.692813890594893,\n",
       "  0.6928255057841226,\n",
       "  0.6928462150706058,\n",
       "  0.6928307101876785,\n",
       "  0.69283541792038,\n",
       "  0.6928216238501014,\n",
       "  0.6928251885386367,\n",
       "  0.6928017175986546,\n",
       "  0.6928060338768969,\n",
       "  0.6928389954518074,\n",
       "  0.6928036482509057,\n",
       "  0.6928090730369065,\n",
       "  0.6928010083115321,\n",
       "  0.6928074522605197,\n",
       "  0.6928188394926108,\n",
       "  0.6928544686246266,\n",
       "  0.6928455379202637,\n",
       "  0.6928026563752161,\n",
       "  0.6928227744276472,\n",
       "  0.6928016428361663,\n",
       "  0.6928076384624487,\n",
       "  0.6928058949582709,\n",
       "  0.6928607289808438,\n",
       "  0.6928518003116917,\n",
       "  0.6928573141421452,\n",
       "  0.6928190371344282,\n",
       "  0.6928178663831523,\n",
       "  0.6928049093525421,\n",
       "  0.6928266923859765,\n",
       "  0.6928122520041201,\n",
       "  0.6928049642261046,\n",
       "  0.6928536277619042,\n",
       "  0.692802100824151,\n",
       "  0.6928131887890776,\n",
       "  0.6928117525171181,\n",
       "  0.6928252921253469,\n",
       "  0.6928293089891983,\n",
       "  0.6928121479908087,\n",
       "  0.6928193174245332,\n",
       "  0.6928015505018223,\n",
       "  0.6928293090279498,\n",
       "  0.692826686331973,\n",
       "  0.6928075938550476,\n",
       "  0.6927995197665938,\n",
       "  0.692821822021725,\n",
       "  0.692796799979116,\n",
       "  0.6928313039776466,\n",
       "  0.692803783204442,\n",
       "  0.6928711745939126,\n",
       "  0.6928046643499652,\n",
       "  0.6928253914357997,\n",
       "  0.6928429891952075,\n",
       "  0.6927975976226082,\n",
       "  0.6928092845192894,\n",
       "  0.6928254081766261,\n",
       "  0.6928026311500423,\n",
       "  0.6927904240427244,\n",
       "  0.692821742888507,\n",
       "  0.6927916266917228,\n",
       "  0.6928046712553743,\n",
       "  0.6928345139749115,\n",
       "  0.6927970866175166,\n",
       "  0.6927945695170127,\n",
       "  0.692790166190711,\n",
       "  0.692820272099411,\n",
       "  0.6928540531573202,\n",
       "  0.692798830640644,\n",
       "  0.6928543118806679,\n",
       "  0.6928140510085499,\n",
       "  0.6928154118060963,\n",
       "  0.6928336487064686,\n",
       "  0.6928094750578231,\n",
       "  0.6928484841949321,\n",
       "  0.692817966714865,\n",
       "  0.6928146864582257,\n",
       "  0.6928140675695237,\n",
       "  0.6928067616053015,\n",
       "  0.6928223878133155,\n",
       "  0.6927992018813498,\n",
       "  0.6928121468967833,\n",
       "  0.6927998775068833,\n",
       "  0.6928146585997238,\n",
       "  0.692785270301872,\n",
       "  0.6928074461447338,\n",
       "  0.6928024591922223,\n",
       "  0.6928097561232768,\n",
       "  0.6927870601914792,\n",
       "  0.6928081108956758,\n",
       "  0.6928046809211367,\n",
       "  0.6928389624975599,\n",
       "  0.6927897726514104,\n",
       "  0.6927936323308092,\n",
       "  0.6928039275935295,\n",
       "  0.6928019054729119,\n",
       "  0.6928030935120656,\n",
       "  0.6927895231059289,\n",
       "  0.6927932424705563,\n",
       "  0.6928006177332191,\n",
       "  0.6928344644312061,\n",
       "  0.6927970858254637,\n",
       "  0.692811500527001,\n",
       "  0.6927868072709071,\n",
       "  0.6927967394827322,\n",
       "  0.6927997651981677,\n",
       "  0.6927894246363949,\n",
       "  0.6928046345643062,\n",
       "  0.6927885083420526,\n",
       "  0.6927912452323416,\n",
       "  0.6928104134186818,\n",
       "  0.6927859132601235,\n",
       "  0.6928092671939285,\n",
       "  0.692803695735777,\n",
       "  0.6927882502372823,\n",
       "  0.6927977744222439,\n",
       "  0.6927902508709575,\n",
       "  0.6927953567823482,\n",
       "  0.692820839653687,\n",
       "  0.6928035840604609,\n",
       "  0.6927979981902059,\n",
       "  0.69282428348146,\n",
       "  0.6927802516875834,\n",
       "  0.6928217462667722,\n",
       "  0.6927848791303178,\n",
       "  0.6927710422998417,\n",
       "  0.6928008235670837,\n",
       "  0.6927769593400311,\n",
       "  0.692808914507551,\n",
       "  0.6927935113720483,\n",
       "  0.6927974167256464,\n",
       "  0.6928127005024514,\n",
       "  0.6927840171435875,\n",
       "  0.6928046924590034,\n",
       "  0.6927822488197906,\n",
       "  0.6928101610800614,\n",
       "  0.6927840366484197,\n",
       "  0.6927854398899653,\n",
       "  0.6928152552036634,\n",
       "  0.6927722208996812,\n",
       "  0.6928190899772295,\n",
       "  0.6927968628876489,\n",
       "  0.6928178620902112,\n",
       "  0.6928001064169289,\n",
       "  0.6927805918586017,\n",
       "  0.6927827930991632,\n",
       "  0.6927657912485821,\n",
       "  0.692829910949593,\n",
       "  0.6927829956202173,\n",
       "  0.6927923669087737,\n",
       "  0.6927750645019739,\n",
       "  0.692783290941835,\n",
       "  0.6927902307116046,\n",
       "  0.6928167490023927,\n",
       "  0.6927687172581056,\n",
       "  0.6927810005239701,\n",
       "  0.6927883998601168,\n",
       "  0.6927685490670241,\n",
       "  0.6927813497532932,\n",
       "  0.6927754578465513,\n",
       "  0.6927775287830263,\n",
       "  0.6927907509692611,\n",
       "  0.6927674914481005,\n",
       "  0.6927974317229338,\n",
       "  0.6928199239725081,\n",
       "  0.6928020718508563,\n",
       "  0.6927953861451172,\n",
       "  0.6927831602024364,\n",
       "  0.6927575557331614,\n",
       "  0.6927672928346309,\n",
       "  0.6927664457447896,\n",
       "  0.6927677729728494,\n",
       "  0.6927988048739343,\n",
       "  0.6927978637421859,\n",
       "  0.6927981872279391,\n",
       "  0.6927676762320052,\n",
       "  0.6927778027113427,\n",
       "  0.6927720224718759,\n",
       "  0.6927759399879608,\n",
       "  0.692785206391807,\n",
       "  0.6928033018777187,\n",
       "  0.6928105077639829,\n",
       "  0.6927667605253511,\n",
       "  0.6927739003949858,\n",
       "  0.692795206596663,\n",
       "  0.6927694374470044,\n",
       "  0.6928045148013748,\n",
       "  0.6927595474004019,\n",
       "  0.6927863638768057,\n",
       "  0.692767658513677,\n",
       "  0.692773366155523,\n",
       "  0.6927789530218593,\n",
       "  0.6927620500202645,\n",
       "  0.6927600655591613,\n",
       "  0.6927970242433811,\n",
       "  0.6927965093952781,\n",
       "  0.6927620039286689,\n",
       "  0.692778463954057,\n",
       "  0.6927585610676277,\n",
       "  0.6927943998311393,\n",
       "  0.6927628543416207,\n",
       "  0.6927748283039474,\n",
       "  0.692791180854069,\n",
       "  0.6927599591527308,\n",
       "  0.6927716990331702,\n",
       "  0.6927798441775088,\n",
       "  0.6927650551227281,\n",
       "  0.6927610259728062,\n",
       "  0.6927636528752161,\n",
       "  0.6927758878466115,\n",
       "  0.6928208687809863,\n",
       "  0.6927551564184862,\n",
       "  0.6927669329952576,\n",
       "  0.6927662360409266,\n",
       "  0.6927663086833675,\n",
       "  0.6927931945652267,\n",
       "  0.692785689007639,\n",
       "  0.69276157366765,\n",
       "  0.6927669883809006,\n",
       "  0.6927535237217051,\n",
       "  0.6927954723052949,\n",
       "  0.6927571001732071,\n",
       "  0.6927541210920382,\n",
       "  0.6927632345981682,\n",
       "  0.6927826970258733,\n",
       "  0.6927566571844249,\n",
       "  0.6927636433167609,\n",
       "  0.6927823662913598,\n",
       "  0.6927497398214026,\n",
       "  0.6927751242134175,\n",
       "  0.6927795503597924,\n",
       "  0.6927445576323148,\n",
       "  0.6927601572804822,\n",
       "  0.6927602457260689,\n",
       "  0.6928304812498689,\n",
       "  0.6927639793862851,\n",
       "  0.6927750671892341,\n",
       "  0.692744649476513,\n",
       "  0.6927900233591673,\n",
       "  0.6927474855565732,\n",
       "  0.6927798726458972,\n",
       "  0.6927653355126397,\n",
       "  0.6927879453517747,\n",
       "  0.692743320300224,\n",
       "  0.6927501921194004,\n",
       "  0.6927545873214932,\n",
       "  0.6927394141354428,\n",
       "  0.6927558228868023,\n",
       "  0.6927645321546196,\n",
       "  0.6927362980825305,\n",
       "  0.6927789584221532,\n",
       "  0.6927708103638242,\n",
       "  0.692746375763955,\n",
       "  0.6927558070088702,\n",
       "  0.6927756317635192,\n",
       "  0.6927617111226576,\n",
       "  0.6927500896817442,\n",
       "  0.692759377327555,\n",
       "  0.6927827762159655,\n",
       "  0.6927541659744323,\n",
       "  0.6927646169159445,\n",
       "  0.6927547886323258,\n",
       "  0.6927465035481074,\n",
       "  0.692759198471551,\n",
       "  0.6927499876430934,\n",
       "  0.6927632772982877,\n",
       "  0.6927465995511013,\n",
       "  0.6927606075756343,\n",
       "  0.6927666225405058,\n",
       "  0.6927330298814262,\n",
       "  0.6927553161006154,\n",
       "  0.6927472869701965,\n",
       "  0.6927593371705507,\n",
       "  0.6927489278424788,\n",
       "  0.6927626110129648,\n",
       "  0.6927602412573661,\n",
       "  0.6927608793343821,\n",
       "  0.6927575708633124,\n",
       "  0.6927346549438174,\n",
       "  0.692757441865824,\n",
       "  0.6927530307381989,\n",
       "  0.6927670067482727,\n",
       "  0.6927333664785581,\n",
       "  0.6927549726249899,\n",
       "  0.6927650360367539,\n",
       "  0.6927511177475497,\n",
       "  0.6927793202951348,\n",
       "  0.6927388319399361,\n",
       "  0.6927482410058474,\n",
       "  0.6927496594574141,\n",
       "  0.6927331778546011,\n",
       "  0.692761090095917,\n",
       "  0.692758596779398,\n",
       "  0.6927355309922493,\n",
       "  0.6927336593981929,\n",
       "  0.6927308559395866,\n",
       "  ...],\n",
       " 'accuracy': [0.390625,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  0.484375,\n",
       "  ...]}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit_history = abc.get_hist()\n",
    "fit_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_fit_history(fit_history, eval_results )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handwritten Digits 0-9 Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to Plot Lists of Digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to plot a list of up to 10 digits on a single subplot\n",
    "def plot_digit_list( a_X_list = None, a_y_list = None, a_find_all_digits = False):\n",
    "    # The first 10 digits from the specified list\n",
    "    \n",
    "    # If no list is specified then return None        \n",
    "    if (a_X_list is None):\n",
    "        return None\n",
    "    \n",
    "    else:\n",
    "        X_list = list(a_X_list)\n",
    "        \n",
    "    if (a_y_list is None):\n",
    "        return None\n",
    "    \n",
    "    else:\n",
    "        y_list = list(a_y_list)\n",
    "        \n",
    "    # Find All Digits flag\n",
    "    #   If True => Find and plot all digits 0-9 within the list, starting at index 0\n",
    "    #   If False => Plot up to the first 10 digits in the list\n",
    "    if a_find_all_digits:\n",
    "\n",
    "        # Flag is True: Get indices of samples for each of the digits 0-9 within the 1000 sample subset\n",
    "        # If the digit is not present in the input list then move on to the next digit\n",
    "        d_i_list = []\n",
    "        for d in range(10):\n",
    "            \n",
    "            try:\n",
    "                # Add the index at which this digit can be found to the list\n",
    "                d_i_list.append( y_list.index(d) )\n",
    "                \n",
    "            except ValueError:\n",
    "                # Digit is not present in the input list -- move on to the next digit\n",
    "                pass\n",
    "\n",
    "    else:\n",
    "        # Flag is False: Get the indices for up to the first 10 values in the list\n",
    "        d_i_list = range( min(10, len(y_list) ))\n",
    "    \n",
    "    # The iterpolation method to use for ploting the digit images\n",
    "    i_type_selected = 'lanczos'\n",
    "\n",
    "    print(\"Indices:\", d_i_list)\n",
    "\n",
    "    # Plot Classification Performance results: Best Score vs. Mean Fit Time (ms)\n",
    "    fig = plt.figure(figsize=(20,9))\n",
    "\n",
    "    # Create subplots for each of the sampled digits\n",
    "    for i in range(len(d_i_list)):\n",
    "        # Create a subplot for this iteration\n",
    "        ax = fig.add_subplot( math.ceil(len(d_i_list)/min(5, len(d_i_list))), min(5, len(d_i_list)), i+1 )\n",
    "\n",
    "        # Display a note for each subplot\n",
    "        point_text = f\"Label: {y_list[d_i_list[i]]}\"\n",
    "        point_text += f\"\\nSample Index: {d_i_list[i]}\"\n",
    "    #     ax.text(1, 2+1.4*point_text.count(\"\\n\"), point_text )\n",
    "        ax.set_title(point_text)\n",
    "\n",
    "        # Display the image\n",
    "        ax.imshow(X_list[d_i_list[i]], cmap=plt.cm.Greys, interpolation=i_type_selected)\n",
    "        \n",
    "    # Return the number of digits plotted\n",
    "    return i+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the MNIST Handwritten Digit Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the Keras MNIST handwritten digits sample dataset\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look for any missing data values in the training labels\n",
    "print( f\"Missing Values - X: {np.sum(X_train == None)}, y: {np.sum(y_train == None)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for imbalance in the training data\n",
    "unique_targets = np.unique(y_train, return_counts=True)\n",
    "unique_targets[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Mean: {np.mean(unique_targets[1])}, Median: {np.median(unique_targets[1])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Max: {np.max(unique_targets[1])}, Min: {np.min(unique_targets[1])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Std Dev: {np.std(unique_targets[1])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20,5))\n",
    "ax1 = fig.add_subplot(1,3,1)\n",
    "ax2 = fig.add_subplot(1,3,2)\n",
    "ax3 = fig.add_subplot(1,3,3)\n",
    "\n",
    "# Column (bar) chart\n",
    "ax1.bar(unique_targets[0], unique_targets[1])\n",
    "\n",
    "# Histogram\n",
    "h_retval = ax2.hist(unique_targets[1])\n",
    "\n",
    "# Boxplot\n",
    "b_retval = ax3.boxplot(unique_targets[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modify the Labels to a Single Class: Target Digit or Not-Target Digit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For this single neuron exploration,\n",
    "# perform a classification for only one digit as either\n",
    "# the target digit or not the target digit\n",
    "TARGET_SINGLE_DIGIT = 3\n",
    "# TARGET_SINGLE_DIGIT = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training and testing arrays that classify the digit as being either TARGET_SINGLE_DIGIT (1) or not (0)\n",
    "y_train_single = np.array([ (1 if y==TARGET_SINGLE_DIGIT else 0) for y in y_train ])\n",
    "print( f\"Training Data: Count of TARGET_SINGLE_DIGIT [{TARGET_SINGLE_DIGIT}] = {np.sum(y_train_single)} occurences [{np.sum(y_train_single) / np.size(y_train_single):0.1%} of {np.size(y_train_single)} total examples]\")\n",
    "print( f\"Training Data: y_train_single (a few samples): {y_train_single[10:20]}\")\n",
    "print(\"\")\n",
    "\n",
    "y_test_single = np.array([ (1 if y==TARGET_SINGLE_DIGIT else 0) for y in y_test ])\n",
    "print( f\"Testing Data: Count of TARGET_SINGLE_DIGIT [{TARGET_SINGLE_DIGIT}] = {np.sum(y_test_single)} occurences [{np.sum(y_test_single) / np.size(y_test_single):0.1%} of {np.size(y_test_single)} total examples]\")\n",
    "print( f\"Testing Data: y_test_single (a few samples): {y_test_single[10:20]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick check to make sure labels are correct\n",
    "check_train_df = pd.DataFrame( { 'y_train': y_train, 'y_train_single': y_train_single }, columns=['y_train', 'y_train_single'])\n",
    "check_test_df = pd.DataFrame( { 'y_test': y_test, 'y_test_single': y_test_single }, columns=['y_test', 'y_test_single'])\n",
    "\n",
    "# Check for occurrences of mismatched labels\n",
    "print( f\"y_train_single: Not the Selected Target Single Digit, but Label == 1 => Occurences { sum( (check_train_df[ 'y_train'] != TARGET_SINGLE_DIGIT) & (check_train_df[ 'y_train_single'] == 1) )}\" )\n",
    "print( f\"y_train_single: Is the Selected Target Single Digit, but Label == 0 => Occurrences { sum( (check_train_df[ 'y_train'] == TARGET_SINGLE_DIGIT) & (check_train_df[ 'y_train_single'] == 0) )}\" )\n",
    "      \n",
    "print( f\"y_test_single: Not the Selected Target Single Digit, but Label == 1 => Occurences { sum( (check_test_df[ 'y_test'] != TARGET_SINGLE_DIGIT) & (check_test_df[ 'y_test_single'] == 1) )}\" )\n",
    "print( f\"y_test_single: Is the Selected Target Single Digit, but Label == 0 => Occurrences { sum( (check_test_df[ 'y_test'] == TARGET_SINGLE_DIGIT) & (check_test_df[ 'y_test_single'] == 0) )}\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot some samples from the training data\n",
    "plot_digit_list(X_train[10:20], y_train_single[10:20], False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot some samples from the testing data\n",
    "# plot_digit_list(X_test[60:70], y_test_single[60:70], False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the current shape of the input and output data\n",
    "print(X_train.shape, y_train_single.shape, X_test.shape, y_test_single.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten the 28x28 pixel images to a 1D array of 784 pixels\n",
    "# and setup the examples in columns (vs. rows)\n",
    "ndims = X_train.shape[1] * X_train.shape[2]\n",
    "X_train_flat = X_train.reshape(X_train.shape[0], ndims)\n",
    "X_test_flat = X_test.reshape(X_test.shape[0], ndims)\n",
    "m_train = X_train_flat.shape[0]\n",
    "m_test = X_test_flat.shape[0]\n",
    "print(X_train_flat.shape, X_test_flat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a scalar to scale the training data to values between 0 and 1 (MinMaxScalar)\n",
    "# Q: How would the results differ if we applied StandardScalar instead of MixMaxScalar\n",
    "x_scalar = MinMaxScaler().fit(X_train_flat)\n",
    "X_train_scaled = x_scalar.transform(X_train_flat)\n",
    "X_test_scaled = x_scalar.transform(X_test_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No need to apply One-Hot Encoding to the labels\n",
    "# because we have limited the classification to only 2 values (0 or 1)\n",
    "n_classes = 2\n",
    "# y_train_encoded = to_categorical(y_train, n_classes)\n",
    "# y_test_encoded = to_categorical(y_test, n_classes)\n",
    "y_train_encoded = y_train_single.reshape(-1,1)\n",
    "y_test_encoded = y_test_single.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the shape of the input and output data\n",
    "print(f\"Features: ndims = {ndims}\")\n",
    "print(f\"Examples: m_train = {m_train}, m_test = {m_test}\")\n",
    "print(f\"Dimensions/Shape: X_train = {X_train_scaled.shape}, y_train = {y_train_encoded.shape}\")\n",
    "print(f\"Dimensions/Shape: X_test = {X_test_scaled.shape}, y_test = {y_test_encoded.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instantiate a Multilayer Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define neural network structure\n",
    "# Input features, one or more hidden layers, outputs\n",
    "all_layers = [ ndims, 10, 10, 1 ]\n",
    "\n",
    "# Instantiate the neural network\n",
    "model = Multilayer_NN(all_layers)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit the model to the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Set random number seed to a known value for easier comparisons later\n",
    "np.random.seed(3)\n",
    "\n",
    "# Use the fit() method to fit the model to the training data\n",
    "# NOTE: Must use transpose of X and y to ensure # of examples is in dimension 1 (vs. 0)\n",
    "model.fit(X_train_scaled.T, y_train_encoded.T, 0.05, 5000, 3000, 1.0)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make Predictions using the fitted model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions using the training data\n",
    "y_act_train = y_train_encoded.T\n",
    "y_pred_train = model.predict(X_train_scaled.T)\n",
    "\n",
    "# Evaluate the performance of the model based upon the training data\n",
    "eval_train = evaluate(y_pred_train, y_act_train )\n",
    "print(f\"Prediction Performance using Training Data ({np.size(y_act_train)} examples):\")\n",
    "print(f\"\\tAccuracy: {eval_train['accuracy']:0.4f}\")\n",
    "print(f\"\\tProbability of Predicting Correctly when Actual Label is Target Digit: {eval_train['proba_label_1']:0.4f}\")\n",
    "print(f\"\\tProbability of Predicting Correctly when Actual Label is Not the Target Digit: {eval_train['proba_label_0']:0.4f}\")\n",
    "print(\"\")\n",
    "\n",
    "# Make predictions using the testing data\n",
    "y_act_test = y_test_encoded.T\n",
    "y_pred_test = model.predict(X_test_scaled.T)\n",
    "\n",
    "# Evaluate the performance of the model based upon the training data\n",
    "eval_test = evaluate(y_pred_test, y_act_test )\n",
    "print(f\"Prediction Performance using Testing Data ({np.size(y_act_test)} examples):\")\n",
    "print(f\"\\tAccuracy: {eval_test['accuracy']:0.4f}\")\n",
    "print(f\"\\tProbability of Predicting Correctly when Actual Label is Target Digit: {eval_test['proba_label_1']:0.4f}\")\n",
    "print(f\"\\tProbability of Predicting Correctly when Actual Label is Not the Target Digit: {eval_test['proba_label_0']:0.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot the Model Fitting History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_results = model.get_hist()\n",
    "plot_fit_history(fit_results, eval_test )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_df = pd.DataFrame( {'Predicted': y_pred_test.reshape(-1), 'Actual': y_act_test.reshape(-1) } )\n",
    "r_df['Correct'] = r_df['Predicted'] == r_df['Actual']\n",
    "\n",
    "len(r_df[ (r_df['Actual'] == 1) & (r_df['Correct'] == True) ]), len(r_df[ (r_df['Actual'] == 1) & (r_df['Correct'] == False) ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "nbpresent": {
   "slides": {
    "03210a56-863e-4749-b7ba-ed75bfceceee": {
     "id": "03210a56-863e-4749-b7ba-ed75bfceceee",
     "prev": "86b3b05f-6e9a-49dc-8a83-97f72c348c5f",
     "regions": {
      "2be9481c-cff7-4f32-b835-90f2a2cb989a": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "46550b81-7dd8-4efc-b710-0f10002c9f2b",
        "part": "whole"
       },
       "id": "2be9481c-cff7-4f32-b835-90f2a2cb989a"
      },
      "3f484569-30ec-4529-8d3c-ac88b8c6dbfb": {
       "attrs": {
        "height": 0.4,
        "width": 0.8,
        "x": 0.1,
        "y": 0.5
       },
       "content": {
        "cell": "2b83c32a-d7e2-4db6-b45f-afbbf028fe90",
        "part": "whole"
       },
       "id": "3f484569-30ec-4529-8d3c-ac88b8c6dbfb"
      }
     }
    },
    "22531930-3fc8-45ff-a4f1-32e94c1d1455": {
     "id": "22531930-3fc8-45ff-a4f1-32e94c1d1455",
     "prev": "8eb735f6-11af-4f77-a4ed-b637fb18ac08",
     "regions": {
      "1407c818-c9fd-470e-8260-6b6904d888de": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "664c64ef-5517-4725-95cb-874bbc7711c7",
        "part": "whole"
       },
       "id": "1407c818-c9fd-470e-8260-6b6904d888de"
      }
     }
    },
    "29c55765-6994-4dbf-b82f-117b4f1e0cee": {
     "id": "29c55765-6994-4dbf-b82f-117b4f1e0cee",
     "prev": "b7c25bc1-4dd7-421b-9951-0c0c403c176d",
     "regions": {
      "44583f15-ec4f-4aec-8e7c-f01652e954fc": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "7c23961d-86fe-4d07-bc58-6d61f03c3731",
        "part": "whole"
       },
       "id": "44583f15-ec4f-4aec-8e7c-f01652e954fc"
      }
     }
    },
    "39c5764b-ab2c-4aae-8500-dc39319e4d38": {
     "id": "39c5764b-ab2c-4aae-8500-dc39319e4d38",
     "prev": "22531930-3fc8-45ff-a4f1-32e94c1d1455",
     "regions": {
      "d0237596-8095-44dc-81c6-6d9c6b204684": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "348e164e-a000-4def-92c0-db93f9a617a1",
        "part": "whole"
       },
       "id": "d0237596-8095-44dc-81c6-6d9c6b204684"
      }
     }
    },
    "39e950f1-f2c4-422a-8f45-835c5c61e7e0": {
     "id": "39e950f1-f2c4-422a-8f45-835c5c61e7e0",
     "prev": "4b5f1824-db4a-4ef3-9515-a88d3f2276c1",
     "regions": {
      "0a72cc48-c38f-4e8c-94d3-3198eccde68a": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "c3820b22-bf55-4dca-ba8b-f08060567b6e",
        "part": "whole"
       },
       "id": "0a72cc48-c38f-4e8c-94d3-3198eccde68a"
      },
      "b49c6eca-318f-41b8-a7a5-a620d18f639c": {
       "attrs": {
        "height": 0.4,
        "width": 0.8,
        "x": 0.1,
        "y": 0.5
       },
       "content": {
        "cell": "aeeeb44d-7825-4050-b7ba-70813bd3396b",
        "part": "whole"
       },
       "id": "b49c6eca-318f-41b8-a7a5-a620d18f639c"
      }
     }
    },
    "4792c0cc-ccd4-48bf-9b0e-a3c1f0f3008d": {
     "id": "4792c0cc-ccd4-48bf-9b0e-a3c1f0f3008d",
     "prev": "39c5764b-ab2c-4aae-8500-dc39319e4d38",
     "regions": {
      "d4adae26-ff2f-4a81-ad91-fd3a9bfd965c": {
       "attrs": {
        "height": 0.4,
        "width": 0.8,
        "x": 0.1,
        "y": 0.5
       },
       "content": {
        "cell": "4d6b8af6-438e-4034-bda1-1f977cf12441",
        "part": "whole"
       },
       "id": "d4adae26-ff2f-4a81-ad91-fd3a9bfd965c"
      },
      "d75a8261-ee89-4f4d-b388-2f429e112f44": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "a3b6e99c-2c85-47da-b29b-3b53c3c309b8",
        "part": "whole"
       },
       "id": "d75a8261-ee89-4f4d-b388-2f429e112f44"
      }
     }
    },
    "4b5f1824-db4a-4ef3-9515-a88d3f2276c1": {
     "id": "4b5f1824-db4a-4ef3-9515-a88d3f2276c1",
     "prev": "e92a9020-6631-400a-aa50-46c1fa0a5f0c",
     "regions": {
      "2bd81133-11e3-48df-bf12-2d0a57949bca": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "69fab88f-0864-47cc-933b-eaffb638cbf3",
        "part": "whole"
       },
       "id": "2bd81133-11e3-48df-bf12-2d0a57949bca"
      },
      "d3322861-28ab-4f1e-8a1f-3a7f4d3da8c1": {
       "attrs": {
        "height": 0.4,
        "width": 0.8,
        "x": 0.1,
        "y": 0.5
       },
       "content": {
        "cell": "3810c2af-fdbe-4f01-bc9f-2bb1a8ae70c6",
        "part": "whole"
       },
       "id": "d3322861-28ab-4f1e-8a1f-3a7f4d3da8c1"
      }
     }
    },
    "57992fb9-2f74-4e8e-8772-7b9f04606a56": {
     "id": "57992fb9-2f74-4e8e-8772-7b9f04606a56",
     "prev": "595093b4-3f86-406c-abb5-aea78e1241b3",
     "regions": {
      "3b3c8191-9f7e-4ab2-afac-b2b47008484a": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "a6d0bdff-9bba-472e-b354-da47b8761dbe",
        "part": "whole"
       },
       "id": "3b3c8191-9f7e-4ab2-afac-b2b47008484a"
      }
     }
    },
    "5907f515-df93-4e86-82c6-b8721b6e6346": {
     "id": "5907f515-df93-4e86-82c6-b8721b6e6346",
     "prev": "39e950f1-f2c4-422a-8f45-835c5c61e7e0",
     "regions": {
      "22f9005a-ed7a-4399-b501-497565ada2da": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "2e255efc-6ae1-4554-b32f-9400b47007c9",
        "part": "whole"
       },
       "id": "22f9005a-ed7a-4399-b501-497565ada2da"
      },
      "82d64cef-48f7-413c-ad01-e7fa2921f7c0": {
       "attrs": {
        "height": 0.4,
        "width": 0.8,
        "x": 0.1,
        "y": 0.5
       },
       "content": {
        "cell": "711a40c8-c479-448b-a3bc-5c7ff8369838",
        "part": "whole"
       },
       "id": "82d64cef-48f7-413c-ad01-e7fa2921f7c0"
      },
      "d943d3ea-6cd3-4d4a-8914-7fea0231efda": {
       "attrs": {
        "height": 0.4,
        "width": 0.8,
        "x": 0.1,
        "y": 0.5
       },
       "content": {
        "cell": "9bfbb27b-cae0-4feb-809a-77718bb2e6a3",
        "part": "whole"
       },
       "id": "d943d3ea-6cd3-4d4a-8914-7fea0231efda"
      }
     }
    },
    "595093b4-3f86-406c-abb5-aea78e1241b3": {
     "id": "595093b4-3f86-406c-abb5-aea78e1241b3",
     "prev": "5907f515-df93-4e86-82c6-b8721b6e6346",
     "regions": {
      "3366a1dc-6c33-45f0-a97f-a2744ed0587f": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "e54b79a1-316d-4fd1-ad5f-6cd580b51f99",
        "part": "whole"
       },
       "id": "3366a1dc-6c33-45f0-a97f-a2744ed0587f"
      },
      "40b6dba8-5994-4fd0-9ce5-9d36f3bb9f93": {
       "attrs": {
        "height": 0.4,
        "width": 0.8,
        "x": 0.1,
        "y": 0.5
       },
       "content": {
        "cell": "3d860568-b048-40f2-a64d-f585211d6c1c",
        "part": "whole"
       },
       "id": "40b6dba8-5994-4fd0-9ce5-9d36f3bb9f93"
      }
     }
    },
    "76838eab-c2c3-4ff3-b09f-854a7c74c6d4": {
     "id": "76838eab-c2c3-4ff3-b09f-854a7c74c6d4",
     "prev": null,
     "regions": {
      "b0032c00-1d89-4c94-a7a0-488f243c381e": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "0dc0cdcb-d8df-4a29-a0d2-a3cf6cc889ce",
        "part": "whole"
       },
       "id": "b0032c00-1d89-4c94-a7a0-488f243c381e"
      }
     }
    },
    "7a25817a-e5bc-4021-9c6b-61bc74dbdb92": {
     "id": "7a25817a-e5bc-4021-9c6b-61bc74dbdb92",
     "prev": "b04719fc-934a-404b-a642-dc732a3d1589",
     "regions": {
      "38d56409-500a-45cf-8e79-722d68d8fc38": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "335f050d-99af-43b3-a5ec-69fe896e48e2",
        "part": "whole"
       },
       "id": "38d56409-500a-45cf-8e79-722d68d8fc38"
      },
      "c838cb6d-409c-4c17-a1eb-3d7dc6aab32b": {
       "attrs": {
        "height": 0.4,
        "width": 0.8,
        "x": 0.1,
        "y": 0.5
       },
       "content": {
        "cell": "19ca6a7e-4b5d-4b0f-88c5-e68634abb65d",
        "part": "whole"
       },
       "id": "c838cb6d-409c-4c17-a1eb-3d7dc6aab32b"
      }
     }
    },
    "86b3b05f-6e9a-49dc-8a83-97f72c348c5f": {
     "id": "86b3b05f-6e9a-49dc-8a83-97f72c348c5f",
     "prev": "57992fb9-2f74-4e8e-8772-7b9f04606a56",
     "regions": {
      "49a41ef6-224d-46c1-bb81-254b8a4cee88": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "d7df6fa0-ce96-4073-b95d-ce78b3f4fdf1",
        "part": "whole"
       },
       "id": "49a41ef6-224d-46c1-bb81-254b8a4cee88"
      },
      "7ce316ab-4799-4e15-b095-374da21bc1aa": {
       "attrs": {
        "height": 0.4,
        "width": 0.8,
        "x": 0.1,
        "y": 0.5
       },
       "content": {
        "cell": "4a5226b5-d431-4cbe-86a6-291952a45a37",
        "part": "whole"
       },
       "id": "7ce316ab-4799-4e15-b095-374da21bc1aa"
      },
      "a7d701c6-61e3-48e3-8e0d-a4b318aef7d8": {
       "attrs": {
        "height": 0.4,
        "width": 0.8,
        "x": 0.1,
        "y": 0.5
       },
       "content": {
        "cell": "5e425283-82de-4c48-b2ae-31a1d6983849",
        "part": "whole"
       },
       "id": "a7d701c6-61e3-48e3-8e0d-a4b318aef7d8"
      },
      "e180cf23-71a7-46a8-8598-86a079bd7d78": {
       "attrs": {
        "height": 0.4,
        "width": 0.8,
        "x": 0.1,
        "y": 0.5
       },
       "content": {
        "cell": "28aaab45-1e14-4db5-9d2c-63b239cafe13",
        "part": "whole"
       },
       "id": "e180cf23-71a7-46a8-8598-86a079bd7d78"
      }
     }
    },
    "8eb735f6-11af-4f77-a4ed-b637fb18ac08": {
     "id": "8eb735f6-11af-4f77-a4ed-b637fb18ac08",
     "prev": "7a25817a-e5bc-4021-9c6b-61bc74dbdb92",
     "regions": {
      "ca38ef02-01f9-42cb-9e35-d67f8d665597": {
       "attrs": {
        "height": 0.4,
        "width": 0.8,
        "x": 0.1,
        "y": 0.5
       },
       "content": {
        "cell": "69b638ed-ed32-4824-bb81-df958c215a33",
        "part": "whole"
       },
       "id": "ca38ef02-01f9-42cb-9e35-d67f8d665597"
      },
      "fc52547b-a8f8-40e2-9397-5b18ca2b71b3": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "7317e4f2-150e-4336-ac48-d82641441aa8",
        "part": "whole"
       },
       "id": "fc52547b-a8f8-40e2-9397-5b18ca2b71b3"
      }
     }
    },
    "af2f5933-b31d-4d30-b08a-e4c09432b9bb": {
     "id": "af2f5933-b31d-4d30-b08a-e4c09432b9bb",
     "prev": "29c55765-6994-4dbf-b82f-117b4f1e0cee",
     "regions": {
      "479b436f-50bb-4c3a-9a4e-748e85eacde6": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "6d53481c-69ff-41a0-937e-4e8a39e2b2b5",
        "part": "whole"
       },
       "id": "479b436f-50bb-4c3a-9a4e-748e85eacde6"
      },
      "a02a5bdc-cab5-4ddc-aa9d-8ee5e0db6bd4": {
       "attrs": {
        "height": 0.4,
        "width": 0.8,
        "x": 0.1,
        "y": 0.5
       },
       "content": {
        "cell": "b0f8400f-71e1-4892-9012-88e54c053a36",
        "part": "whole"
       },
       "id": "a02a5bdc-cab5-4ddc-aa9d-8ee5e0db6bd4"
      }
     }
    },
    "b04719fc-934a-404b-a642-dc732a3d1589": {
     "id": "b04719fc-934a-404b-a642-dc732a3d1589",
     "prev": "af2f5933-b31d-4d30-b08a-e4c09432b9bb",
     "regions": {
      "701cdc94-3399-40dc-8e45-10d6edbf0959": {
       "attrs": {
        "height": 0.4,
        "width": 0.8,
        "x": 0.1,
        "y": 0.5
       },
       "content": {
        "cell": "fa78fa75-54cf-40d3-b52c-4b51c5070d9a",
        "part": "whole"
       },
       "id": "701cdc94-3399-40dc-8e45-10d6edbf0959"
      },
      "81f01069-a0c6-4ab1-98d1-d465e96aac6d": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "fb58a52c-71e9-402d-af86-eab194cf8050",
        "part": "whole"
       },
       "id": "81f01069-a0c6-4ab1-98d1-d465e96aac6d"
      },
      "ae73fc9b-89cf-4405-ab54-34e6c8b73a19": {
       "attrs": {
        "height": 0.4,
        "width": 0.8,
        "x": 0.1,
        "y": 0.5
       },
       "content": {
        "cell": "241f356d-567a-421d-b27c-7ce2d146d1bb",
        "part": "whole"
       },
       "id": "ae73fc9b-89cf-4405-ab54-34e6c8b73a19"
      }
     }
    },
    "b7c25bc1-4dd7-421b-9951-0c0c403c176d": {
     "id": "b7c25bc1-4dd7-421b-9951-0c0c403c176d",
     "prev": "76838eab-c2c3-4ff3-b09f-854a7c74c6d4",
     "regions": {
      "47f524f5-68f8-49df-9a61-61eab6cab03c": {
       "attrs": {
        "height": 0.4,
        "width": 0.8,
        "x": 0.1,
        "y": 0.5
       },
       "content": {
        "cell": "966e050d-5739-4ef9-a2ae-9a4957e14f3e",
        "part": "whole"
       },
       "id": "47f524f5-68f8-49df-9a61-61eab6cab03c"
      },
      "4b3ba01a-29e7-4e67-ac78-988162f7dde9": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "91401f60-44eb-42b2-86ea-c82b5e955ace",
        "part": "whole"
       },
       "id": "4b3ba01a-29e7-4e67-ac78-988162f7dde9"
      },
      "a47d9662-0a49-4b84-aae0-908067552ebd": {
       "attrs": {
        "height": 0.4,
        "width": 0.8,
        "x": 0.1,
        "y": 0.5
       },
       "content": {
        "cell": "6de4dae8-c949-4927-89a3-9741aba83e8d",
        "part": "whole"
       },
       "id": "a47d9662-0a49-4b84-aae0-908067552ebd"
      },
      "e64668fe-aafe-4e24-a46d-6a6266eeee77": {
       "attrs": {
        "height": 0.4,
        "width": 0.8,
        "x": 0.1,
        "y": 0.5
       },
       "content": {
        "cell": "7068c96d-f8f0-42bb-bdfd-dcbf9335323c",
        "part": "whole"
       },
       "id": "e64668fe-aafe-4e24-a46d-6a6266eeee77"
      }
     }
    },
    "d3ecec0a-67fe-4558-a268-50695fd7fe1c": {
     "id": "d3ecec0a-67fe-4558-a268-50695fd7fe1c",
     "prev": "fcda7de6-cb93-4b63-9dea-d5f23fecd968",
     "regions": {
      "b268bb57-2543-4b91-b9c0-84aa3cf09d5c": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "67aab8fa-45cd-4ede-8285-e3dad22d8b16",
        "part": "whole"
       },
       "id": "b268bb57-2543-4b91-b9c0-84aa3cf09d5c"
      }
     }
    },
    "e92a9020-6631-400a-aa50-46c1fa0a5f0c": {
     "id": "e92a9020-6631-400a-aa50-46c1fa0a5f0c",
     "prev": "ee94ae9b-9e13-414c-a017-db1d8913aaa8",
     "regions": {
      "bb15b4ea-132f-4146-ab77-93a4969c2904": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "7d5d2002-5cae-4d5f-8e2e-d5eaf5cd17da",
        "part": "whole"
       },
       "id": "bb15b4ea-132f-4146-ab77-93a4969c2904"
      }
     }
    },
    "ee94ae9b-9e13-414c-a017-db1d8913aaa8": {
     "id": "ee94ae9b-9e13-414c-a017-db1d8913aaa8",
     "prev": "f8fce519-927e-4fd0-88d8-23ece4403794",
     "regions": {
      "0b578bb1-2cd1-480b-8d65-dde0861851cb": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "f1c699bc-6717-4eb9-8e6d-66d433ba4618",
        "part": "whole"
       },
       "id": "0b578bb1-2cd1-480b-8d65-dde0861851cb"
      }
     }
    },
    "f8fce519-927e-4fd0-88d8-23ece4403794": {
     "id": "f8fce519-927e-4fd0-88d8-23ece4403794",
     "prev": "4792c0cc-ccd4-48bf-9b0e-a3c1f0f3008d",
     "regions": {
      "7510ae01-fe22-48b0-92cb-29b880cc85fc": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "e61ba538-5828-4a5a-a2c5-4fcceac35889",
        "part": "whole"
       },
       "id": "7510ae01-fe22-48b0-92cb-29b880cc85fc"
      }
     }
    },
    "fcda7de6-cb93-4b63-9dea-d5f23fecd968": {
     "id": "fcda7de6-cb93-4b63-9dea-d5f23fecd968",
     "prev": "03210a56-863e-4749-b7ba-ed75bfceceee",
     "regions": {
      "43f5b3bd-9e0c-4a98-a18c-1b9f7beaa3b8": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "318099ba-93dd-4c2c-a3ee-fc6622c472c8",
        "part": "whole"
       },
       "id": "43f5b3bd-9e0c-4a98-a18c-1b9f7beaa3b8"
      },
      "dbab9920-f08a-457a-949d-2c8289707798": {
       "attrs": {
        "height": 0.4,
        "width": 0.8,
        "x": 0.1,
        "y": 0.5
       },
       "content": {
        "cell": "8bb35ef7-00cc-4ad9-9dd4-6fac480df38e",
        "part": "whole"
       },
       "id": "dbab9920-f08a-457a-949d-2c8289707798"
      }
     }
    }
   },
   "themes": {}
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
